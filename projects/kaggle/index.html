<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Housing price prediction | Mohan Ramesh</title> <meta name="author" content="Mohan Ramesh"/> <meta name="description" content="an inter university kaggle competetion"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zybermonk.github.io/projects/kaggle/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Mohan </span>Ramesh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blogs</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Housing price prediction</h1> <p class="post-description">an inter university kaggle competetion</p> </header> <article> <ul> <li>Author: Mohan Ramesh</li> <li>University of Limerick private competetion</li> <li>P.S: Git repo will be linked here soon</li> </ul> <h1 id="summary">Summary:</h1> <p>House pricing is almost as much an art as a theory. There are many contributing factors that decide the price of the house and many approaches to solve the difficulty of the issue. In this research, I studied the housing market from a numerical and non-numeric standpoint and was able to formulate a range of approaches that were aimed at price forecasts. What I found most surprising is the propensity of homebuyers to give preference to the visual aspects and their feeling about the area when making their buying decisions. Many psychological experiments have been conducted about what helps people decide to buy the single most significant purchase of their lives, but only a few studies have used graphics in their price forecasts. Since half the decision has been taken by our sense of sight, I decided to do housing image classification and house pricing by using numerical data,categorical data, text description(advertising) along with its corresponding image.</p> <p>Below is a Schematic I created to represent the model we see throughout this notebook.</p> <div> <figure> <picture> <img src="/assets/img/projects/kaggle/schema.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h3 id="xgboost-stands-for-extreme-gradient-boosting">XGBoost stands for extreme Gradient Boosting.</h3> <p>The name xgboost, though, actually refers to the engineering goal to push the limit of computations resources for boosted tree algorithms. Which is the reason I make use of xgboost to solve our problem.</p> <p>The house price dataset we are using includes Numerical data, Categorical data, Text data and Image data as well. So, we tackle each type of data differently.</p> <ul> <li>The first 3 types of data are tackled locally using Feature Engieering methods, Different types of encoding, NML decomposers, Randomized search for selecting best hyperparameters.</li> <li>Whereas the image data is trained using Google Colab’s TPU by a pre-trained Deep Neural Network called ResNet-50, and features are extracted at the pre-final layer ready to be fed to the XGBoost regressor.</li> </ul> <p>So, This Solution follows a Basic Data Visualization, followed by Feature Engineering, Then Building a model to train and finally Deploying it. Let’s look at every step, one by one:</p> <h1 id="data-visualization">Data Visualization</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">'''Import necessary libraries '''</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div> <p>see what data looks like. First few rows.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ad_id</th> <th>area</th> <th>bathrooms</th> <th>beds</th> <th>ber_classification</th> <th>county</th> <th>description_block</th> <th>environment</th> <th>facility</th> <th>features</th> <th>latitude</th> <th>longitude</th> <th>no_of_units</th> <th>price</th> <th>property_category</th> <th>property_type</th> <th>surface</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>996887</td> <td>Portmarnock</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>Dublin</td> <td>A SELECTION OF 4 AND 5 BEDROOM FAMILY HOMES LO...</td> <td>prod</td> <td>NaN</td> <td>None</td> <td>53.418216</td> <td>-6.149329</td> <td>18.0</td> <td>NaN</td> <td>new_development_parent</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1</th> <td>999327</td> <td>Lucan</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>Dublin</td> <td>**Last 2 remaining houses for sale ***\n\nOn v...</td> <td>prod</td> <td>NaN</td> <td>None</td> <td>53.364917</td> <td>-6.454935</td> <td>3.0</td> <td>NaN</td> <td>new_development_parent</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>999559</td> <td>Rathfarnham</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>Dublin</td> <td>Final 4 &amp;amp; 5 Bedroom Homes for Sale\n\nOn V...</td> <td>prod</td> <td>NaN</td> <td>None</td> <td>53.273447</td> <td>-6.313821</td> <td>3.0</td> <td>NaN</td> <td>new_development_parent</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>9102986</td> <td>Balbriggan</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>Dublin</td> <td>Glenveagh Taylor Hill, Balbriggan\n\r\n*Ideal ...</td> <td>prod</td> <td>NaN</td> <td>None</td> <td>53.608167</td> <td>-6.210914</td> <td>30.0</td> <td>NaN</td> <td>new_development_parent</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>9106028</td> <td>Foxrock</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>Dublin</td> <td>*New phase launching this weekend Sat &amp;amp; Su...</td> <td>prod</td> <td>NaN</td> <td>None</td> <td>53.262531</td> <td>-6.181527</td> <td>8.0</td> <td>NaN</td> <td>new_development_parent</td> <td>NaN</td> <td>NaN</td> </tr> </tbody> </table> </div> <p>Check for NULL values</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ad_id                    0
area                     0
bathrooms               51
beds                    51
ber_classification     677
county                   0
description_block        0
environment              0
facility              2017
features                 0
latitude                 0
longitude                0
no_of_units           2923
price                   90
property_category        0
property_type           51
surface                551
dtype: int64
</code></pre></div></div> <p>We can see a few columns have a lot of NULL values. We need to Check if that’s the case for test data set as well. Then we have to Handle these NULL values accordingly.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 2982 entries, 0 to 2981
Data columns (total 17 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   ad_id               2982 non-null   int64  
 1   area                2982 non-null   object 
 2   bathrooms           2931 non-null   float64
 3   beds                2931 non-null   float64
 4   ber_classification  2305 non-null   object 
 5   county              2982 non-null   object 
 6   description_block   2982 non-null   object 
 7   environment         2982 non-null   object 
 8   facility            965 non-null    object 
 9   features            2982 non-null   object 
 10  latitude            2982 non-null   float64
 11  longitude           2982 non-null   float64
 12  no_of_units         59 non-null     float64
 13  price               2892 non-null   float64
 14  property_category   2982 non-null   object 
 15  property_type       2931 non-null   object 
 16  surface             2431 non-null   float64
dtypes: float64(7), int64(1), object(9)
memory usage: 396.2+ KB
</code></pre></div></div> <p>Here in the above result we see that the dataset is a mixed type of dataset, and but manually looking at the columns we see that bathrooms and beds are actually categories, but is given as a number. The columns county and environment are actually useless as they contain 1 unique category only. And the column no_of_units is not really necessary because almost all of the values are NULL, which we later see that no_of_units in the test dataset is actually empty. Then we can also decide to keep the text features like description_block, features and facility aside for a while, and only look at the rest of the features.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">numerical</span> <span class="o">=</span> <span class="p">[</span><span class="s">'price'</span><span class="p">,</span> <span class="s">'latitude'</span><span class="p">,</span> <span class="s">'longitude'</span><span class="p">,</span> <span class="s">'surface'</span><span class="p">]</span>
<span class="n">categorical</span> <span class="o">=</span> <span class="p">[</span><span class="s">'area'</span><span class="p">,</span> <span class="s">'ber_classification'</span><span class="p">,</span> <span class="s">'property_category'</span><span class="p">,</span> <span class="s">'property_type'</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="n">numerical</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">));</span>
</code></pre></div></div> <div> <figure> <picture> <img src="/assets/img/projects/kaggle/output_16_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>We see all of the Numerical values are skewed</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">variable</span><span class="p">,</span> <span class="n">subplot</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">categorical</span><span class="p">,</span> <span class="n">ax</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()):</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">countplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">variable</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">subplot</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">subplot</span><span class="p">.</span><span class="nf">get_xticklabels</span><span class="p">():</span>
        <span class="n">label</span><span class="p">.</span><span class="nf">set_rotation</span><span class="p">(</span><span class="mi">90</span><span class="p">)</span>
</code></pre></div></div> <div> <figure> <picture> <img src="/assets/img/projects/kaggle/output_18_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Now we have a general idea of what the data looks like and lets proceed to Feature Engieering and Feature selection.</p> <h1 id="feature-engineering-and-selection">Feature Engineering and Selection</h1> <p>We already discarded several columns by manual evaluation of train and test sets, and we also know what are categorical features and what are Numerical. So lets handle these columns individually.</p> <p>The ‘ad_id’ column is to be dropped logically since it is an unique value. But I decide to keep it in this case, as I noticed a strange relationship between the ad_id and the price. As there is a common prefix among group of houses.</p> <p>bathrooms and beds columns are actually categories so I change their dtype</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">beds</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'beds'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">beds</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</code></pre></div></div> <p>Now I fill all the NULL values:</p> <ul> <li>Categorical : With Mode()</li> <li>Numerical : With Mean() of the respective columns.</li> </ul> <p>And drop the redundant columns, inferred manually.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="nf">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'beds'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'beds'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'beds'</span><span class="p">].</span><span class="nf">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'ber_classification'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'ber_classification'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'ber_classification'</span><span class="p">].</span><span class="nf">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'county'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'environment'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"facility"</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="s">"low"</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'no_of_units'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s">'property_type'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'property_type'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'property_type'</span><span class="p">].</span><span class="nf">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'surface'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'surface'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'surface'</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
</code></pre></div></div> <p>lets plot the features to see if there are any null values</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span><span class="n">yticklabels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1f1e0b147c0&gt;
</code></pre></div></div> <div> <figure> <picture> <img src="/assets/img/projects/kaggle/output_28_1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h3 id="now-lets-load-the-test-dataset-which-has-undergone-the-same-features-engineering-methods-as-train-data">Now lets load the test dataset, which has undergone the same features engineering methods as train data</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'test_prep.csv'</span><span class="p">)</span> <span class="c1"># test data is handled seperately and only shown here.
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">test_df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span><span class="n">yticklabels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">'summer'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1f1e1449280&gt;
</code></pre></div></div> <div> <figure> <picture> <img src="/assets/img/projects/kaggle/output_31_1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h3 id="now-lets-start-encoding">Now Lets start encoding</h3> <p>Before encoding we make sure encoding is being performed on both train and test sets, because there might be categories which are different (more/less) from each other.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span><span class="n">test_df</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h1 id="label-encoding-the-ordinal-categories">Label Encoding the Ordinal Categories</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="p">[</span><span class="s">"bathrooms"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"bathrooms"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="s">'category'</span><span class="p">)</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"beds"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"beds"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="s">'category'</span><span class="p">)</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"ber_classification"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"ber_classification"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="s">'category'</span><span class="p">)</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"facility"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"facility"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="s">'category'</span><span class="p">)</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"bathrooms"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"bathrooms"</span><span class="p">].</span><span class="n">cat</span><span class="p">.</span><span class="n">codes</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"beds"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"beds"</span><span class="p">].</span><span class="n">cat</span><span class="p">.</span><span class="n">codes</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"ber_classification"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"ber_classification"</span><span class="p">].</span><span class="n">cat</span><span class="p">.</span><span class="n">codes</span>
<span class="n">final_df</span><span class="p">[</span><span class="s">"facility"</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="s">"facility"</span><span class="p">].</span><span class="n">cat</span><span class="p">.</span><span class="n">codes</span>
</code></pre></div></div> <h1 id="one-hot-encoding-the-nominal-categories">One Hot Encoding the Nominal Categories</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'area'</span><span class="p">,</span><span class="s">'property_category'</span><span class="p">,</span><span class="s">'property_type'</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">category_onehot_multcols</span><span class="p">(</span><span class="n">multcolumns</span><span class="p">):</span>
    <span class="n">df_final</span><span class="o">=</span><span class="n">final_df</span>
    <span class="n">i</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">fields</span> <span class="ow">in</span> <span class="n">multcolumns</span><span class="p">:</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>
        <span class="n">df1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="n">fields</span><span class="p">],</span><span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">final_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="n">fields</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">df_final</span><span class="o">=</span><span class="n">df1</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            
            <span class="n">df_final</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df_final</span><span class="p">,</span><span class="n">df1</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>
       
        
    <span class="n">df_final</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">final_df</span><span class="p">,</span><span class="n">df_final</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">df_final</span>

<span class="n">final_df</span><span class="o">=</span><span class="nf">category_onehot_multcols</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>area
property_category
property_type
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(3482, 177)
</code></pre></div></div> <h3 id="now-we-include-text-features">Now We include Text features.</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nmf_df</span> <span class="o">=</span> <span class="n">final_df</span>
</code></pre></div></div> <p>we vectorize each of the text columns and tokenize the top words in them</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">tfidf1</span> <span class="o">=</span> <span class="nc">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">dtm_with_tfidf_des</span> <span class="o">=</span> <span class="n">tfidf1</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">nmf_df</span><span class="p">[</span><span class="s">'description_block'</span><span class="p">])</span>
<span class="n">dtm_with_tfidf_des</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;3482x6207 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
	with 544865 stored elements in Compressed Sparse Row format&gt;
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">tfidf2</span> <span class="o">=</span> <span class="nc">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">dtm_with_tfidf_fea</span> <span class="o">=</span> <span class="n">tfidf2</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">nmf_df</span><span class="p">[</span><span class="s">'features'</span><span class="p">])</span>
<span class="n">dtm_with_tfidf_fea</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;3482x1441 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
	with 62245 stored elements in Compressed Sparse Row format&gt;
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="n">nmf_model1</span> <span class="o">=</span> <span class="nc">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nmf_model1</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">dtm_with_tfidf_des</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NMF(n_components=10, random_state=1)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="n">nmf_model2</span> <span class="o">=</span> <span class="nc">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nmf_model2</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">dtm_with_tfidf_fea</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NMF(n_components=10, random_state=1)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">word_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">probability_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">top_number</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">probability_number</span> <span class="ow">in</span> <span class="n">nmf_model1</span><span class="p">.</span><span class="n">components_</span><span class="p">:</span> <span class="c1"># model.components contains the prob of each word for each doc
</span>    <span class="n">text_message</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"Top words for house </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s"> are : "</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">text_message</span><span class="p">)</span>    
    <span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="n">probability_number</span><span class="p">.</span><span class="nf">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">top_number</span><span class="p">:]:</span> <span class="c1"># we're only interested in the top words
</span>        <span class="nf">print</span><span class="p">([</span><span class="n">tfidf1</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">()[</span><span class="n">number</span><span class="p">]],</span> <span class="n">end</span><span class="o">=</span> <span class="s">""</span><span class="p">)</span>
        <span class="n">word_list</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">tfidf1</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">()[</span><span class="n">number</span><span class="p">]])</span>
        <span class="n">probability_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
    <span class="c1">#show_chart(word_list, probability_list, text_message)
</span>    <span class="nf">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>  
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Top words for house 0 are : 
['dining']['double']['garage']['home']['family']['large']['bedroom']['rear']['room']['garden']

Top words for house 1 are : 
['park']['area']['location']['amenities']['road']['excellent']['city']['centre']['dublin']['property']

Top words for house 2 are : 
['room']['spacious']['communal']['bathroom']['floor']['development']['bedroom']['living']['balcony']['apartment']

Top words for house 3 are : 
['factual']['concern']['mistakes']['early']['strongly']['wilson']['care']['leonard']['provided']['information']

Top words for house 4 are : 
['basin']['wash']['hand']['tiled']['lighting']['room']['floor']['window']['recessed']['ceiling']

Top words for house 5 are : 
['lounge']['heating']['right']['advised']['ft']['turn']['left']['auctioneers']['cooke']['ray']

Top words for house 6 are : 
['point']['bedroom']['built']['wood']['carpet']['11']['10']['tiled']['amp']['floor']

Top words for house 7 are : 
['0m']['1m']['9m']['7m']['4m']['6m']['2m']['3m']['8m']['5m']

Top words for house 8 are : 
['intending']['behalf']['contained']['measurement']['given']['description']['shall']['vendor']['hunters']['moovingo']

Top words for house 9 are : 
['wc']['double']['built']['wardrobes']['carpet']['bedroom']['tiled']['laminate']['wood']['flooring']
</code></pre></div></div> <p>This above function for description_block may throw an error: Then increase the components to 20, and reset to 10, this is due to the random state, and when iteration starts from 0, where description_block of certain houses are None.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">probability</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">top</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">counts</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">probability_number</span> <span class="ow">in</span> <span class="n">nmf_model2</span><span class="p">.</span><span class="n">components_</span><span class="p">:</span> <span class="c1"># model.components contains the prob of each word for each doc
</span>    <span class="n">text_message</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"Top words for house </span><span class="si">{</span><span class="n">counts</span><span class="si">}</span><span class="s"> are : "</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">text_message</span><span class="p">)</span>    
    <span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="n">probability_number</span><span class="p">.</span><span class="nf">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">top</span><span class="p">:]:</span> <span class="c1"># we're only interested in the top words
</span>        <span class="nf">print</span><span class="p">([</span><span class="n">tfidf2</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">()[</span><span class="n">number</span><span class="p">]],</span> <span class="n">end</span><span class="o">=</span> <span class="s">""</span><span class="p">)</span>
        <span class="nb">list</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">tfidf2</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">()[</span><span class="n">number</span><span class="p">]])</span>
        <span class="n">probability</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
    <span class="c1">#show_chart(list, probability, text_message)
</span>    <span class="nf">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>  
    <span class="n">counts</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Top words for house 0 are : 
['sunny']['private']['gfch']['parking']['street']['west']['south']['facing']['rear']['garden']

Top words for house 1 are : 
['underground']['secure']['car']['management']['balcony']['designated']['parking']['floor']['space']['apartment']

Top words for house 2 are : 
['parking']['location']['rear']['accommodation']['alarm']['oil']['fired']['heating']['gas']['central']

Top words for house 3 are : 
['extend']['family']['planning']['house']['semi']['subject']['garage']['potential']['detached']['large']

Top words for house 4 are : 
['family']['convenient']['accommodation']['extending']['floor']['approximately']['area']['approx']['ft']['sq']

Top words for house 5 are : 
['dining']['open']['fully']['bathroom']['new']['modern']['living']['fitted']['room']['kitchen']

Top words for house 6 are : 
['access']['walk']['m50']['luas']['bus']['dublin']['city']['walking']['distance']['centre']

Top words for house 7 are : 
['guest']['sash']['bedrooms']['alarm']['doors']['upvc']['pvc']['windows']['glazed']['double']

Top words for house 8 are : 
['end']['extended']['located']['condition']['private']['green']['location']['quiet']['sac']['cul']

Top words for house 9 are : 
['superb']['schools']['links']['condition']['transport']['local']['location']['amenities']['excellent']['close']
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">topic1</span> <span class="o">=</span> <span class="n">nmf_model1</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">dtm_with_tfidf_des</span><span class="p">)</span>
<span class="n">topic2</span> <span class="o">=</span> <span class="n">nmf_model2</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">dtm_with_tfidf_fea</span><span class="p">)</span>
<span class="n">des</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fea</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">index_pos</span> <span class="ow">in</span> <span class="n">topic1</span><span class="p">:</span>
    <span class="n">des</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index_pos</span><span class="p">.</span><span class="nf">argmax</span><span class="p">())</span>
    
<span class="k">for</span> <span class="n">index_pos</span> <span class="ow">in</span> <span class="n">topic2</span><span class="p">:</span>
    <span class="n">fea</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index_pos</span><span class="p">.</span><span class="nf">argmax</span><span class="p">())</span>

<span class="n">final_df</span><span class="p">[</span><span class="s">'description_block'</span><span class="p">]</span> <span class="o">=</span> <span class="n">des</span>    
<span class="n">final_df</span><span class="p">[</span><span class="s">'features'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fea</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span>
</code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ad_id</th> <th>bathrooms</th> <th>beds</th> <th>ber_classification</th> <th>description_block</th> <th>facility</th> <th>features</th> <th>latitude</th> <th>longitude</th> <th>price</th> <th>...</th> <th>sale</th> <th>bungalow</th> <th>detached</th> <th>duplex</th> <th>end-of-terrace</th> <th>semi-detached</th> <th>site</th> <th>studio</th> <th>terraced</th> <th>townhouse</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>996887</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>35</td> <td>0</td> <td>53.418216</td> <td>-6.149329</td> <td>532353.590941</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>1</th> <td>999327</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>35</td> <td>0</td> <td>53.364917</td> <td>-6.454935</td> <td>532353.590941</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>2</th> <td>999559</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>35</td> <td>0</td> <td>53.273447</td> <td>-6.313821</td> <td>532353.590941</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>3</th> <td>9102986</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>35</td> <td>0</td> <td>53.608167</td> <td>-6.210914</td> <td>532353.590941</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>4</th> <td>9106028</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>35</td> <td>0</td> <td>53.262531</td> <td>-6.181527</td> <td>532353.590941</td> <td>...</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>495</th> <td>12369815</td> <td>2</td> <td>2</td> <td>9</td> <td>2</td> <td>35</td> <td>1</td> <td>53.342207</td> <td>-6.226101</td> <td>NaN</td> <td>...</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>496</th> <td>12416011</td> <td>5</td> <td>5</td> <td>11</td> <td>8</td> <td>12</td> <td>9</td> <td>53.261475</td> <td>-6.147720</td> <td>NaN</td> <td>...</td> <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>497</th> <td>12232222</td> <td>3</td> <td>3</td> <td>14</td> <td>7</td> <td>35</td> <td>8</td> <td>53.391619</td> <td>-6.205157</td> <td>NaN</td> <td>...</td> <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>498</th> <td>11905630</td> <td>4</td> <td>4</td> <td>12</td> <td>0</td> <td>20</td> <td>5</td> <td>53.360578</td> <td>-6.183701</td> <td>NaN</td> <td>...</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> <tr> <th>499</th> <td>12394865</td> <td>2</td> <td>2</td> <td>6</td> <td>3</td> <td>35</td> <td>1</td> <td>53.366827</td> <td>-6.248329</td> <td>NaN</td> <td>...</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> </tr> </tbody> </table> <p>3482 rows × 177 columns</p> </div> <p>We can see from this output, that the description_block and the features columns have transformed into a categorical feature with 10 labels each, based on top keywords present in their columns.</p> <h3 id="here-comes-the-image-data-i-directly-load-a-csv-file-which-was-exported-from-resnet50-model-training">Here comes the image data. I directly load a .csv file which was exported from resnet50 model training</h3> <p>Below is a link to the resnet 50 model I used to extract features from the image dataset.</p> <ul> <li>https://colab.research.google.com/drive/1PY9uP058KPp8X_C2-OYdDvPSC7550f6G</li> </ul> <h3 id="including-image-features-trained-from-a-resnet-50--code-included-in-seperate-notebook">Including Image features trained from a ResNet 50. Code included in seperate Notebook.</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'colab.csv'</span><span class="p">)</span> <span class="c1"># this was trained in an other environment and only shown here.
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span> <span class="o">=</span> <span class="n">image_df</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span>
</code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ad_id</th> <th>bathrooms</th> <th>beds</th> <th>ber_classification</th> <th>description_block</th> <th>features</th> <th>latitude</th> <th>longitude</th> <th>price</th> <th>surface</th> <th>...</th> <th>img_feature_2039</th> <th>img_feature_2040</th> <th>img_feature_2041</th> <th>img_feature_2042</th> <th>img_feature_2043</th> <th>img_feature_2044</th> <th>img_feature_2045</th> <th>img_feature_2046</th> <th>img_feature_2047</th> <th>facility</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>996887</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>0</td> <td>53.418216</td> <td>-6.149329</td> <td>532353.590941</td> <td>318.851787</td> <td>...</td> <td>0.346182</td> <td>1.348307</td> <td>0.000000</td> <td>0.005628</td> <td>0.000000</td> <td>1.184270</td> <td>0.127480</td> <td>1.594526</td> <td>1.213027</td> <td>35</td> </tr> <tr> <th>1</th> <td>999327</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>0</td> <td>53.364917</td> <td>-6.454935</td> <td>532353.590941</td> <td>318.851787</td> <td>...</td> <td>0.026714</td> <td>0.740785</td> <td>0.000000</td> <td>0.079070</td> <td>0.000000</td> <td>3.622611</td> <td>0.371412</td> <td>0.289070</td> <td>0.949369</td> <td>35</td> </tr> <tr> <th>2</th> <td>999559</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>0</td> <td>53.273447</td> <td>-6.313821</td> <td>532353.590941</td> <td>318.851787</td> <td>...</td> <td>0.401499</td> <td>2.237763</td> <td>0.072135</td> <td>0.967058</td> <td>0.000000</td> <td>1.819107</td> <td>0.143481</td> <td>0.509172</td> <td>0.331188</td> <td>35</td> </tr> <tr> <th>3</th> <td>9102986</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>0</td> <td>53.608167</td> <td>-6.210914</td> <td>532353.590941</td> <td>318.851787</td> <td>...</td> <td>0.070776</td> <td>0.130126</td> <td>0.004703</td> <td>0.001361</td> <td>0.000000</td> <td>2.277957</td> <td>0.280137</td> <td>0.000000</td> <td>1.162026</td> <td>35</td> </tr> <tr> <th>4</th> <td>9106028</td> <td>3</td> <td>3</td> <td>9</td> <td>1</td> <td>0</td> <td>53.262531</td> <td>-6.181527</td> <td>532353.590941</td> <td>318.851787</td> <td>...</td> <td>0.116760</td> <td>0.202983</td> <td>0.000000</td> <td>0.143929</td> <td>0.000000</td> <td>1.624645</td> <td>0.112375</td> <td>0.376265</td> <td>0.638939</td> <td>35</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>3477</th> <td>12369815</td> <td>2</td> <td>2</td> <td>9</td> <td>2</td> <td>1</td> <td>53.342207</td> <td>-6.226101</td> <td>NaN</td> <td>65.000000</td> <td>...</td> <td>0.000778</td> <td>0.304676</td> <td>0.028688</td> <td>0.224259</td> <td>0.004548</td> <td>0.962055</td> <td>0.108555</td> <td>1.107376</td> <td>0.278461</td> <td>35</td> </tr> <tr> <th>3478</th> <td>12416011</td> <td>5</td> <td>5</td> <td>11</td> <td>8</td> <td>9</td> <td>53.261475</td> <td>-6.147720</td> <td>NaN</td> <td>191.300000</td> <td>...</td> <td>0.046760</td> <td>1.183030</td> <td>0.000000</td> <td>0.080099</td> <td>0.000000</td> <td>0.218454</td> <td>0.126472</td> <td>0.296787</td> <td>0.084717</td> <td>12</td> </tr> <tr> <th>3479</th> <td>12232222</td> <td>3</td> <td>3</td> <td>14</td> <td>7</td> <td>8</td> <td>53.391619</td> <td>-6.205157</td> <td>NaN</td> <td>105.000000</td> <td>...</td> <td>0.000000</td> <td>2.081742</td> <td>0.011908</td> <td>0.000000</td> <td>0.000000</td> <td>0.523524</td> <td>0.229754</td> <td>0.109374</td> <td>0.574645</td> <td>35</td> </tr> <tr> <th>3480</th> <td>11905630</td> <td>4</td> <td>4</td> <td>12</td> <td>0</td> <td>5</td> <td>53.360578</td> <td>-6.183701</td> <td>NaN</td> <td>130.000000</td> <td>...</td> <td>0.115299</td> <td>1.064319</td> <td>0.000000</td> <td>0.045372</td> <td>0.000000</td> <td>0.515674</td> <td>0.572230</td> <td>0.703695</td> <td>0.291449</td> <td>20</td> </tr> <tr> <th>3481</th> <td>12394865</td> <td>2</td> <td>2</td> <td>6</td> <td>3</td> <td>1</td> <td>53.366827</td> <td>-6.248329</td> <td>NaN</td> <td>71.000000</td> <td>...</td> <td>0.223927</td> <td>0.487077</td> <td>0.010795</td> <td>0.004007</td> <td>0.000000</td> <td>0.685754</td> <td>0.032210</td> <td>0.001133</td> <td>0.951588</td> <td>35</td> </tr> </tbody> </table> <p>3482 rows × 2260 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3482 entries, 0 to 3481
Columns: 2260 entries, ad_id to facility
dtypes: float64(2052), int64(208)
memory usage: 60.0 MB
</code></pre></div></div> <p>Now we have a really big file to train!!</p> <h1 id="model-training">Model Training</h1> <p>Resplitting into Train and Test</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_Train</span><span class="o">=</span><span class="n">final_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">2982</span><span class="p">,:]</span>
<span class="n">df_Test</span><span class="o">=</span><span class="n">final_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2982</span><span class="p">:,:]</span>
<span class="nf">print</span><span class="p">(</span><span class="s">'train size'</span><span class="p">,</span><span class="n">df_Train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="s">'test size'</span><span class="p">,</span><span class="n">df_Test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train size (2982, 2260)
test size (500, 2260)
</code></pre></div></div> <p>Creating datasets to feed to model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_X</span><span class="o">=</span><span class="n">df_Train</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'price'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_Y</span><span class="o">=</span><span class="n">df_Train</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
<span class="n">test_X</span><span class="o">=</span><span class="n">df_Test</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'price'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <p>Import the Regressor to Train</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">xgboost</span>
<span class="n">xgb</span><span class="o">=</span><span class="n">xgboost</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">booster</span><span class="o">=</span><span class="p">[</span><span class="s">'gbtree'</span><span class="p">,</span><span class="s">'gblinear'</span><span class="p">]</span>
<span class="n">base_score</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.75</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <p>When you observe high training accuracy, but low test accuracy, it is likely that you encountered overfitting problem. There are in general two ways that you can control overfitting in XGBoost:</p> <ol> <li> <p>The first way is to directly control model complexity. -This includes max_depth, min_child_weight and gamma.</p> </li> <li> <p>The second way is to add randomness to make training robust to noise. -This includes subsample and colsample_bytree.</p> </li> </ol> <p>You can also reduce stepsize eta. Remember to increase num_round when you do so.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="mi">1100</span><span class="p">,</span> <span class="mi">1500</span><span class="p">]</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">booster</span><span class="o">=</span><span class="p">[</span><span class="s">'gbtree'</span><span class="p">,</span><span class="s">'gblinear'</span><span class="p">]</span>
<span class="n">learning_rate</span><span class="o">=</span><span class="p">[</span><span class="mf">0.20</span><span class="p">,</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.05</span><span class="p">]</span>
<span class="n">min_child_weight</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>

<span class="c1"># Define the grid of hyperparameters to search
</span><span class="n">hyperparameter_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
    <span class="s">'max_depth'</span><span class="p">:</span><span class="n">max_depth</span><span class="p">,</span>
    <span class="s">'learning_rate'</span><span class="p">:</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="s">'min_child_weight'</span><span class="p">:</span><span class="n">min_child_weight</span><span class="p">,</span>
    <span class="s">'booster'</span><span class="p">:</span><span class="n">booster</span><span class="p">,</span>
    <span class="s">'base_score'</span><span class="p">:</span><span class="n">base_score</span>
    <span class="p">}</span>
</code></pre></div></div> <p>Import Random search to find the best parameters</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set up the random search with 4-fold cross validation
</span><span class="n">random_cv</span> <span class="o">=</span> <span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">xgb</span><span class="p">,</span>
            <span class="n">param_distributions</span><span class="o">=</span><span class="n">hyperparameter_grid</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">scoring</span> <span class="o">=</span> <span class="s">'neg_mean_absolute_error'</span><span class="p">,</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
            <span class="n">return_train_score</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <p>This uses a 4 fold cross validation, number of cpu cores used are 4 (n_jobs = 4)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 50 candidates, totalling 250 fits


[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    9.2s
[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  1.5min
[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  3.0min
[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  4.6min finished





RandomizedSearchCV(cv=5,
                   estimator=XGBRegressor(base_score=None, booster=None,
                                          colsample_bylevel=None,
                                          colsample_bynode=None,
                                          colsample_bytree=None, gamma=None,
                                          gpu_id=None, importance_type='gain',
                                          interaction_constraints=None,
                                          learning_rate=None,
                                          max_delta_step=None, max_depth=None,
                                          min_child_weight=None, missing=nan,
                                          monotone_constraints=None,
                                          n_estimators=100, n...
                                          validate_parameters=None,
                                          verbosity=None),
                   n_iter=50, n_jobs=4,
                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],
                                        'booster': ['gbtree', 'gblinear'],
                                        'learning_rate': [0.2, 0.15, 0.1, 0.05],
                                        'max_depth': [2, 3, 5, 10, 15],
                                        'min_child_weight': [1, 2, 3, 4],
                                        'n_estimators': [100, 500, 900, 1100,
                                                         1500]},
                   random_state=42, return_train_score=True,
                   scoring='neg_mean_absolute_error', verbose=5)
</code></pre></div></div> <p>The parameter estimation here is done for a subset of the dataset, hence the time taken is substantial. In practice, the whole dataset is to be trained to estimate the best parameters, hence we can obtain a better result.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_cv</span><span class="p">.</span><span class="n">best_estimator_</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
             importance_type='gain', interaction_constraints='',
             learning_rate=0.1, max_delta_step=0, max_depth=5,
             min_child_weight=4, missing=nan, monotone_constraints='()',
             n_estimators=500, n_jobs=0, num_parallel_tree=1, random_state=0,
             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,
             tree_method='exact', validate_parameters=1, verbosity=None)
</code></pre></div></div> <p>There’s a parameter called tree_method, set it to hist or gpu_hist for faster computation. But I use ‘exact’, as suggested by the best parameter estimation.</p> <h1 id="deploy">Deploy</h1> <p>now we add these parameters to our regressor training model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb</span><span class="o">=</span><span class="n">xgboost</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">(</span><span class="n">base_score</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span> <span class="n">colsample_bylevel</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">colsample_bynode</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">colsample_bytree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">gpu_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">importance_type</span><span class="o">=</span><span class="s">'gain'</span><span class="p">,</span> <span class="n">interaction_constraints</span><span class="o">=</span><span class="s">''</span><span class="p">,</span>
             <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_delta_step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
             <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">monotone_constraints</span><span class="o">=</span><span class="s">'()'</span><span class="p">,</span>
             <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_parallel_tree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
             <span class="n">reg_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reg_lambda</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">tree_method</span><span class="o">=</span><span class="s">'exact'</span><span class="p">,</span> <span class="n">validate_parameters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <h3 id="learning">Learning</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
             importance_type='gain', interaction_constraints='',
             learning_rate=0.1, max_delta_step=0, max_depth=5,
             min_child_weight=4, missing=None, monotone_constraints='()',
             n_estimators=500, n_jobs=0, num_parallel_tree=1, random_state=0,
             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,
             tree_method='exact', validate_parameters=1, verbosity=None)
</code></pre></div></div> <h3 id="prediction">Prediction</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array_pred</span><span class="o">=</span><span class="n">xgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array_pred</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 780835.  ,  382269.75,  454439.16,  393493.84,  271353.  ,
        351030.75,  390479.06, 1077982.2 ,  380722.4 ,  574778.06],
      dtype=float32)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">array_pred</span><span class="p">)</span>
</code></pre></div></div> <h1 id="creating-a-submission-file">Creating a Submission file</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred</span>
</code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>0</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>7.808350e+05</td> </tr> <tr> <th>1</th> <td>3.822698e+05</td> </tr> <tr> <th>2</th> <td>4.544392e+05</td> </tr> <tr> <th>3</th> <td>3.934938e+05</td> </tr> <tr> <th>4</th> <td>2.713530e+05</td> </tr> <tr> <th>...</th> <td>...</td> </tr> <tr> <th>495</th> <td>3.537192e+05</td> </tr> <tr> <th>496</th> <td>1.001171e+06</td> </tr> <tr> <th>497</th> <td>3.957671e+05</td> </tr> <tr> <th>498</th> <td>7.106702e+05</td> </tr> <tr> <th>499</th> <td>3.261407e+05</td> </tr> </tbody> </table> <p>500 rows × 1 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sub_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'Submission_file.csv'</span><span class="p">)</span> <span class="c1">#reading old submission file
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sub_df</span>
</code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Id</th> <th>Predicted</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>12373510</td> <td>701423.248581</td> </tr> <tr> <th>1</th> <td>12422623</td> <td>561985.537703</td> </tr> <tr> <th>2</th> <td>12377408</td> <td>837755.712440</td> </tr> <tr> <th>3</th> <td>12420093</td> <td>834321.906203</td> </tr> <tr> <th>4</th> <td>12417338</td> <td>425684.666076</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> </tr> <tr> <th>495</th> <td>12369815</td> <td>286286.445489</td> </tr> <tr> <th>496</th> <td>12416011</td> <td>977124.710212</td> </tr> <tr> <th>497</th> <td>12232222</td> <td>425818.933065</td> </tr> <tr> <th>498</th> <td>11905630</td> <td>701328.471883</td> </tr> <tr> <th>499</th> <td>12394865</td> <td>422429.355953</td> </tr> </tbody> </table> <p>500 rows × 2 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">datasets</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">sub_df</span><span class="p">[</span><span class="s">'Id'</span><span class="p">],</span><span class="n">pred</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">datasets</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Id'</span><span class="p">,</span><span class="s">'Predicted'</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">datasets</span> <span class="c1">#new file
</span></code></pre></div></div> <div class="table-wrapper"> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Id</th> <th>Predicted</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>12373510</td> <td>7.808350e+05</td> </tr> <tr> <th>1</th> <td>12422623</td> <td>3.822698e+05</td> </tr> <tr> <th>2</th> <td>12377408</td> <td>4.544392e+05</td> </tr> <tr> <th>3</th> <td>12420093</td> <td>3.934938e+05</td> </tr> <tr> <th>4</th> <td>12417338</td> <td>2.713530e+05</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> </tr> <tr> <th>495</th> <td>12369815</td> <td>3.537192e+05</td> </tr> <tr> <th>496</th> <td>12416011</td> <td>1.001171e+06</td> </tr> <tr> <th>497</th> <td>12232222</td> <td>3.957671e+05</td> </tr> <tr> <th>498</th> <td>11905630</td> <td>7.106702e+05</td> </tr> <tr> <th>499</th> <td>12394865</td> <td>3.261407e+05</td> </tr> </tbody> </table> <p>500 rows × 2 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">datasets</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="s">'Submission_file.csv'</span><span class="p">)</span>
</code></pre></div></div> <p>Now this Submission_file is uploaded to the kaggle environment to check for performance.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Mohan Ramesh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>