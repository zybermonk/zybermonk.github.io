<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The simulation hypothesis | Mohan Ramesh</title> <meta name="author" content="Mohan Ramesh"/> <meta name="description" content="A space to document and discuss science and life! "/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zybermonk.github.io/news/announcement_2/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Mohan </span>Ramesh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blogs</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">The simulation hypothesis</h1> <p class="post-meta">March 25, 2021</p> <p class="post-tags"> <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </header> <article class="post-content"> <p>This is an idea that I am currently fascinated about. I will be working on this for a good amount of time, so feel free to reach out to join in on this research. All backgrounds welcome :)</p> <hr> <h1 id="introduction">Introduction</h1> <p>End is near, is it? We have been hearing this over the past couple of decades. Is it just an irrational fideism or maybe the prophecies have an error of -10+ , -100+ and so on. Schmidhuber try to extend the naive analysis of past computer science breakthroughs in the intro-duction, which predicts that computer history will converge in an Omega point or historic singularity X around 2040. Could it be that such lists just reflect the human way of allocating memory space to past events Maybe there is a general rule for both the individual memory of single humans and the collective memory of entire societies and their history books. He basically tries to say if history repeats itself, which is the first research which I try to answer through my project.</p> <p>1) <a href="https://people.idsia.ch/~juergen/history.html" target="_blank" rel="noopener noreferrer">Will History Converge?</a> Is it a co-incidence or if there is a pattern repeating itself? This research question will be answered based on the research question 2.</p> <p>One of the breakthroughs that can cause this next big revolution is the creation of a super Intelligence, or more specifically, Artificial General Intelligence. According to the above convergence hypothesis, we are due to see this AGI in the next few decades. This idea gives rise to my second research question, that is,</p> <p>2) What is the possibility of such an AGI to come into existence, if Yes, what is probability of an intelligence explosion?</p> <p>[ There are two possible types of intelligence speedup: one due to faster operation of an intelligent system (clock speed increase or the hardware) and one due to an improvement in the type of mechanisms that implement the thought processes (‘‘depth of thought’’ increase or the software). Obviously, both could occur at once (and there may be significant synergies), but the latter is ostensibly more difficult to achieve, and may be subject to fundamental limits that we do not understand. Speeding up the hardware, on the other hand, is something that has been going on for a long time and is more mundane and reliable. Notice that both routes lead to greater ‘‘intelligence,’’ because even a human level of thinking and creativity would be more effective if it were happening a thousand times faster than it does now. It seems possible that the general class of AGI systems can be architected to take better advantage of improved hardware than would be the case with intelligent systems very narrowly imitative of the human brain. But even if this is not the case, brute hardware speedup can still yield dramatic intelligent improvement.] This section of text from <a href="https://lists.extropy.org/pipermail/extropy-chat/2011-January/063255.html" target="_blank" rel="noopener noreferrer">Richard Loosemore</a>, suggests that the explosion can be measured and we can clearly discard limiting factors such as investment ability, software complexity and hardware advancement.</p> <p><strong>Hypothesis :</strong> Once an AI system with roughly human-level general intelligence is created, an ‘‘intelligence explosion’’ involving the relatively rapid creation of increasingly more generally intelligent AI systems will very likely ensue, resulting in the rapid emergence of dramatically superhuman intelligences.</p> <p><strong>Null Hypothesis :</strong> No creation of that SEED AGI to begin with.</p> <h1 id="papers-in-the-field-and-data-sources">Papers in the field and Data Sources</h1> <ol> <li> <p><a href="https://uol.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_askewsholts_vlebooks_9783642325601&amp;context=PC&amp;vid=353UOL_INST:353UOL_VU1&amp;lang=en&amp;search_scope=MyInst_and_CI&amp;adaptor=Primo%20Central&amp;tab=TAB1&amp;query=any,contains,singularity%20hypothesis&amp;sortby=rank" target="_blank" rel="noopener noreferrer">The Main Book</a> – UL Glucksman Library</p> </li> <li> <p><a href="https://link.springer.com/chapter/10.1007/978-3-642-32560-1_4" target="_blank" rel="noopener noreferrer">Research Question 1</a></p> </li> <li> <p><a href="https://lists.extropy.org/pipermail/extropy-chat/2011-January/063255.html" target="_blank" rel="noopener noreferrer">Research Question 2</a></p> </li> <li> <p><a href="https://otexts.com/fpp2/forecasting-regression.html" target="_blank" rel="noopener noreferrer">Forecasting model data</a> and <a href="https://commons.wikimedia.org/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg" target="_blank" rel="noopener noreferrer">Human level AGI forecast</a></p> </li> </ol> <p><strong>Relevant research:</strong></p> <blockquote> <p>Baum, S. D., Goertzel, B., &amp; Goertzel, T. G. (2011). How long until human-level AI? results from an expert assessment. Technological Forecasting and Social Change, 78(1), 185–195.</p> </blockquote> <blockquote> <p>Chalmers, D. (2010). The singularity: A philosophical analysis. Journal of Consciousness Studies, 17, 7–65.</p> </blockquote> <blockquote> <p>Goertzel, B. (2010). Toward a formal characterization of real-world general intelligence. Proceedings of AGI-10, Lugano.</p> </blockquote> <blockquote> <p>Hutter, M. (2005). Universal AI. Berlin: Springer.</p> </blockquote> <blockquote> <p>Sandberg, A. (2011, January 19). Limiting factors of intelligence explosion speeds. Extropy email</p> </blockquote> <p><strong>Data Sources:</strong></p> <p><a href="https://fred.stlouisfed.org/series/Y006RC1Q027SBEA" target="_blank" rel="noopener noreferrer">Private investment</a></p> <p><a href="https://ourworldindata.org/grapher/research-and-development-expenditure-of-gdp?tab=chart&amp;country=~OWID_WRL" target="_blank" rel="noopener noreferrer">Global GDP share on R&amp;D</a></p> <p><a href="https://ourworldindata.org/grapher/supercomputer-power-flops?time=earliest..2020" target="_blank" rel="noopener noreferrer">Super-Computer Power</a></p> <p><a href="https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-09-03" target="_blank" rel="noopener noreferrer">Hardware Data</a></p> <p><a href="https://ourworldindata.org/technological-progress" target="_blank" rel="noopener noreferrer">Transistors per Chip</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Mohan Ramesh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>